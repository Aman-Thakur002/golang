/*
=============================================================================
                        ğŸ‘· GO WORKER POOLS TUTORIAL
=============================================================================

ğŸ“š CORE CONCEPT:
Worker pools are a concurrency pattern where a fixed number of goroutines
(workers) process jobs from a shared queue. This pattern provides controlled
concurrency and efficient resource utilization.

ğŸ”‘ KEY FEATURES:
â€¢ Controlled concurrency with fixed worker count
â€¢ Job queue for distributing work
â€¢ Result collection and error handling
â€¢ Graceful shutdown and cleanup

ğŸ’¡ REAL-WORLD ANALOGY:
Worker Pool = Restaurant Kitchen
- Workers = Chefs working in parallel
- Job queue = Order tickets waiting to be prepared
- Results = Completed dishes ready to serve
- Pool size = Number of chefs on duty

ğŸ¯ WHY USE WORKER POOLS?
â€¢ Limit resource usage (memory, connections)
â€¢ Process large amounts of work efficiently
â€¢ Control system load and prevent overload
â€¢ Implement rate limiting and backpressure

=============================================================================
*/

package main

import (
	"fmt"
	"math/rand"
	"sync"
	"time"
)

// ğŸ“‹ JOB DEFINITIONS
type Job struct {
	ID   int
	Data string
}

type Result struct {
	Job    Job
	Output string
	Error  error
}

// ğŸ­ BASIC WORKER POOL
func basicWorkerPool() {
	fmt.Println("ğŸ­ Basic Worker Pool")
	fmt.Println("===================")

	const numWorkers = 3
	const numJobs = 10

	// Create channels
	jobs := make(chan Job, numJobs)
	results := make(chan Result, numJobs)

	// Start workers
	var wg sync.WaitGroup
	for w := 1; w <= numWorkers; w++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()
			for job := range jobs {
				fmt.Printf("Worker %d processing job %d\n", id, job.ID)
				
				// Simulate work
				time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond)
				
				// Send result
				results <- Result{
					Job:    job,
					Output: fmt.Sprintf("Processed by worker %d", id),
					Error:  nil,
				}
			}
			fmt.Printf("Worker %d finished\n", id)
		}(w)
	}

	// Send jobs
	go func() {
		for j := 1; j <= numJobs; j++ {
			jobs <- Job{ID: j, Data: fmt.Sprintf("job-%d", j)}
		}
		close(jobs)
	}()

	// Collect results
	go func() {
		wg.Wait()
		close(results)
	}()

	// Process results
	for result := range results {
		fmt.Printf("Result: Job %d -> %s\n", result.Job.ID, result.Output)
	}
}

// ğŸ¯ ADVANCED WORKER POOL WITH STRUCT
type WorkerPool struct {
	workers    int
	jobQueue   chan Job
	resultChan chan Result
	quit       chan bool
	wg         sync.WaitGroup
}

func NewWorkerPool(workers int, queueSize int) *WorkerPool {
	return &WorkerPool{
		workers:    workers,
		jobQueue:   make(chan Job, queueSize),
		resultChan: make(chan Result, queueSize),
		quit:       make(chan bool),
	}
}

func (wp *WorkerPool) Start() {
	for i := 0; i < wp.workers; i++ {
		wp.wg.Add(1)
		go wp.worker(i + 1)
	}
}

func (wp *WorkerPool) worker(id int) {
	defer wp.wg.Done()
	
	for {
		select {
		case job := <-wp.jobQueue:
			fmt.Printf("ğŸ”§ Worker %d processing job %d\n", id, job.ID)
			
			// Simulate processing time
			processingTime := time.Duration(rand.Intn(500)+100) * time.Millisecond
			time.Sleep(processingTime)
			
			// Simulate occasional errors
			var err error
			if rand.Float32() < 0.1 { // 10% error rate
				err = fmt.Errorf("processing failed for job %d", job.ID)
			}
			
			result := Result{
				Job:    job,
				Output: fmt.Sprintf("Completed by worker %d in %v", id, processingTime),
				Error:  err,
			}
			
			wp.resultChan <- result
			
		case <-wp.quit:
			fmt.Printf("ğŸ›‘ Worker %d stopping\n", id)
			return
		}
	}
}

func (wp *WorkerPool) Submit(job Job) {
	wp.jobQueue <- job
}

func (wp *WorkerPool) Results() <-chan Result {
	return wp.resultChan
}

func (wp *WorkerPool) Stop() {
	close(wp.quit)
	wp.wg.Wait()
	close(wp.jobQueue)
	close(wp.resultChan)
}

// ğŸ“Š BATCH PROCESSOR
type BatchProcessor struct {
	workerPool *WorkerPool
	batchSize  int
	timeout    time.Duration
}

func NewBatchProcessor(workers, queueSize, batchSize int, timeout time.Duration) *BatchProcessor {
	return &BatchProcessor{
		workerPool: NewWorkerPool(workers, queueSize),
		batchSize:  batchSize,
		timeout:    timeout,
	}
}

func (bp *BatchProcessor) ProcessBatch(jobs []Job) []Result {
	bp.workerPool.Start()
	defer bp.workerPool.Stop()

	// Submit all jobs
	for _, job := range jobs {
		bp.workerPool.Submit(job)
	}

	// Collect results with timeout
	var results []Result
	timeout := time.After(bp.timeout)
	
	for i := 0; i < len(jobs); i++ {
		select {
		case result := <-bp.workerPool.Results():
			results = append(results, result)
		case <-timeout:
			fmt.Printf("â° Timeout reached, collected %d/%d results\n", len(results), len(jobs))
			return results
		}
	}
	
	return results
}

// ğŸŒ HTTP REQUEST WORKER POOL EXAMPLE
type URLJob struct {
	ID  int
	URL string
}

type URLResult struct {
	Job        URLJob
	StatusCode int
	Error      error
	Duration   time.Duration
}

func httpWorkerPool() {
	fmt.Println("\nğŸŒ HTTP Request Worker Pool")
	fmt.Println("===========================")

	const numWorkers = 5
	urls := []string{
		"https://httpbin.org/delay/1",
		"https://httpbin.org/delay/2",
		"https://httpbin.org/status/200",
		"https://httpbin.org/status/404",
		"https://httpbin.org/status/500",
	}

	jobs := make(chan URLJob, len(urls))
	results := make(chan URLResult, len(urls))

	// Start workers
	var wg sync.WaitGroup
	for w := 1; w <= numWorkers; w++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()
			for job := range jobs {
				start := time.Now()
				
				// Simulate HTTP request
				fmt.Printf("ğŸŒ Worker %d requesting %s\n", id, job.URL)
				time.Sleep(time.Duration(rand.Intn(1000)+500) * time.Millisecond)
				
				// Simulate response
				statusCode := 200
				if rand.Float32() < 0.2 {
					statusCode = 500
				}
				
				results <- URLResult{
					Job:        job,
					StatusCode: statusCode,
					Duration:   time.Since(start),
					Error:      nil,
				}
			}
		}(w)
	}

	// Submit jobs
	for i, url := range urls {
		jobs <- URLJob{ID: i + 1, URL: url}
	}
	close(jobs)

	// Wait for workers and close results
	go func() {
		wg.Wait()
		close(results)
	}()

	// Collect results
	for result := range results {
		status := "âœ…"
		if result.StatusCode >= 400 {
			status = "âŒ"
		}
		fmt.Printf("%s Job %d: %s -> %d (%v)\n", 
			status, result.Job.ID, result.Job.URL, result.StatusCode, result.Duration)
	}
}

func main() {
	fmt.Println("ğŸ‘· WORKER POOLS TUTORIAL")
	fmt.Println("========================")

	// Seed random number generator
	rand.Seed(time.Now().UnixNano())

	// ğŸ¯ DEMO 1: Basic Worker Pool
	basicWorkerPool()

	// ğŸ¯ DEMO 2: Advanced Worker Pool
	fmt.Println("\nğŸ¯ Advanced Worker Pool")
	fmt.Println("=======================")

	pool := NewWorkerPool(4, 20)
	pool.Start()

	// Submit jobs
	numJobs := 15
	go func() {
		for i := 1; i <= numJobs; i++ {
			job := Job{
				ID:   i,
				Data: fmt.Sprintf("task-%d", i),
			}
			pool.Submit(job)
		}
	}()

	// Collect results
	var successCount, errorCount int
	for i := 0; i < numJobs; i++ {
		result := <-pool.Results()
		if result.Error != nil {
			fmt.Printf("âŒ Job %d failed: %v\n", result.Job.ID, result.Error)
			errorCount++
		} else {
			fmt.Printf("âœ… Job %d: %s\n", result.Job.ID, result.Output)
			successCount++
		}
	}

	pool.Stop()
	fmt.Printf("ğŸ“Š Summary: %d successful, %d failed\n", successCount, errorCount)

	// ğŸ¯ DEMO 3: Batch Processor
	fmt.Println("\nğŸ¯ Batch Processor")
	fmt.Println("==================")

	batchProcessor := NewBatchProcessor(3, 10, 5, 5*time.Second)
	
	// Create batch of jobs
	var batchJobs []Job
	for i := 1; i <= 8; i++ {
		batchJobs = append(batchJobs, Job{
			ID:   i,
			Data: fmt.Sprintf("batch-job-%d", i),
		})
	}

	fmt.Printf("Processing batch of %d jobs...\n", len(batchJobs))
	results := batchProcessor.ProcessBatch(batchJobs)
	
	fmt.Printf("Batch completed: %d results\n", len(results))
	for _, result := range results {
		if result.Error != nil {
			fmt.Printf("âŒ Batch job %d: %v\n", result.Job.ID, result.Error)
		} else {
			fmt.Printf("âœ… Batch job %d: %s\n", result.Job.ID, result.Output)
		}
	}

	// ğŸ¯ DEMO 4: HTTP Worker Pool (simulated)
	httpWorkerPool()

	// ğŸ¯ DEMO 5: Performance Comparison
	fmt.Println("\nğŸ¯ Performance Comparison")
	fmt.Println("=========================")

	// Sequential processing
	start := time.Now()
	fmt.Println("Sequential processing...")
	for i := 1; i <= 10; i++ {
		time.Sleep(100 * time.Millisecond) // Simulate work
	}
	sequentialTime := time.Since(start)
	fmt.Printf("Sequential time: %v\n", sequentialTime)

	// Parallel processing with worker pool
	start = time.Now()
	fmt.Println("Parallel processing with worker pool...")
	
	parallelPool := NewWorkerPool(5, 10)
	parallelPool.Start()

	// Submit jobs
	for i := 1; i <= 10; i++ {
		parallelPool.Submit(Job{ID: i, Data: fmt.Sprintf("perf-test-%d", i)})
	}

	// Collect results
	for i := 0; i < 10; i++ {
		<-parallelPool.Results()
	}

	parallelPool.Stop()
	parallelTime := time.Since(start)
	fmt.Printf("Parallel time: %v\n", parallelTime)
	fmt.Printf("Speedup: %.2fx\n", float64(sequentialTime)/float64(parallelTime))

	fmt.Println("\nâœ¨ All worker pool demos completed!")
}

/*
=============================================================================
                              ğŸ“ LEARNING NOTES
=============================================================================

ğŸ‘· WORKER POOL PATTERN:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ // Basic structure                                                      â”‚
â”‚ jobs := make(chan Job, queueSize)                                       â”‚
â”‚ results := make(chan Result, queueSize)                                 â”‚
â”‚                                                                         â”‚
â”‚ // Start workers                                                        â”‚
â”‚ for w := 1; w <= numWorkers; w++ {                                      â”‚
â”‚     go func(id int) {                                                   â”‚
â”‚         for job := range jobs {                                         â”‚
â”‚             // Process job                                              â”‚
â”‚             result := processJob(job)                                   â”‚
â”‚             results <- result                                           â”‚
â”‚         }                                                               â”‚
â”‚     }(w)                                                                â”‚
â”‚ }                                                                       â”‚
â”‚                                                                         â”‚
â”‚ // Submit jobs                                                          â”‚
â”‚ for _, job := range jobList {                                           â”‚
â”‚     jobs <- job                                                         â”‚
â”‚ }                                                                       â”‚
â”‚ close(jobs)                                                             â”‚
â”‚                                                                         â”‚
â”‚ // Collect results                                                      â”‚
â”‚ for i := 0; i < len(jobList); i++ {                                     â”‚
â”‚     result := <-results                                                 â”‚
â”‚     // Handle result                                                    â”‚
â”‚ }                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ WORKER POOL COMPONENTS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ type WorkerPool struct {                                                â”‚
â”‚     workers    int              // Number of worker goroutines          â”‚
â”‚     jobQueue   chan Job         // Channel for incoming jobs            â”‚
â”‚     resultChan chan Result      // Channel for results                  â”‚
â”‚     quit       chan bool        // Channel for shutdown signal          â”‚
â”‚     wg         sync.WaitGroup   // Wait for workers to finish           â”‚
â”‚ }                                                                       â”‚
â”‚                                                                         â”‚
â”‚ // Key methods                                                          â”‚
â”‚ func (wp *WorkerPool) Start()                // Start workers           â”‚
â”‚ func (wp *WorkerPool) Submit(job Job)        // Submit job              â”‚
â”‚ func (wp *WorkerPool) Results() <-chan Result // Get results channel    â”‚
â”‚ func (wp *WorkerPool) Stop()                 // Graceful shutdown       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”§ IMPLEMENTATION PATTERNS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ // Worker function with select                                          â”‚
â”‚ func (wp *WorkerPool) worker(id int) {                                  â”‚
â”‚     for {                                                               â”‚
â”‚         select {                                                        â”‚
â”‚         case job := <-wp.jobQueue:                                      â”‚
â”‚             // Process job                                              â”‚
â”‚             result := processJob(job)                                   â”‚
â”‚             wp.resultChan <- result                                     â”‚
â”‚         case <-wp.quit:                                                 â”‚
â”‚             return                                                      â”‚
â”‚         }                                                               â”‚
â”‚     }                                                                   â”‚
â”‚ }                                                                       â”‚
â”‚                                                                         â”‚
â”‚ // Graceful shutdown                                                    â”‚
â”‚ func (wp *WorkerPool) Stop() {                                          â”‚
â”‚     close(wp.quit)        // Signal workers to stop                     â”‚
â”‚     wp.wg.Wait()          // Wait for workers to finish                 â”‚
â”‚     close(wp.jobQueue)    // Close job queue                            â”‚
â”‚     close(wp.resultChan)  // Close result channel                       â”‚
â”‚ }                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š SIZING CONSIDERATIONS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ // Worker count guidelines                                              â”‚
â”‚ â€¢ CPU-bound tasks: runtime.NumCPU()                                     â”‚
â”‚ â€¢ I/O-bound tasks: Higher count (10-100+ workers)                       â”‚
â”‚ â€¢ Memory-limited: Consider memory per worker                            â”‚
â”‚ â€¢ External API: Respect rate limits                                     â”‚
â”‚                                                                         â”‚
â”‚ // Queue size guidelines                                                â”‚
â”‚ â€¢ Small queue: Better backpressure, less memory                         â”‚
â”‚ â€¢ Large queue: Better throughput, more memory                           â”‚
â”‚ â€¢ Buffered channels: len(jobs) = 2-10x number of workers                â”‚
â”‚                                                                         â”‚
â”‚ // Monitoring metrics                                                   â”‚
â”‚ â€¢ Queue length: len(jobQueue)                                           â”‚
â”‚ â€¢ Active workers: Track in worker function                              â”‚
â”‚ â€¢ Processing time: Measure per job                                      â”‚
â”‚ â€¢ Error rate: Track failed jobs                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš¡ PERFORMANCE OPTIMIZATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ // Batch processing                                                     â”‚
â”‚ type Batch []Job                                                        â”‚
â”‚ func processBatch(batch Batch) []Result {                               â”‚
â”‚     // Process multiple jobs together                                   â”‚
â”‚ }                                                                       â”‚
â”‚                                                                         â”‚
â”‚ // Worker pools with different priorities                               â”‚
â”‚ highPriorityJobs := make(chan Job, 100)                                 â”‚
â”‚ lowPriorityJobs := make(chan Job, 1000)                                 â”‚
â”‚                                                                         â”‚
â”‚ // Worker with priority handling                                        â”‚
â”‚ select {                                                                â”‚
â”‚ case job := <-highPriorityJobs:                                         â”‚
â”‚     // Process high priority job                                        â”‚
â”‚ case job := <-lowPriorityJobs:                                          â”‚
â”‚     // Process low priority job                                         â”‚
â”‚ case <-quit:                                                            â”‚
â”‚     return                                                              â”‚
â”‚ }                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ BEST PRACTICES:
â€¢ Size worker pool based on workload characteristics
â€¢ Use buffered channels for better performance
â€¢ Implement graceful shutdown with context or quit channel
â€¢ Monitor queue length and processing times
â€¢ Handle errors gracefully and provide retry mechanisms
â€¢ Use timeouts for long-running jobs
â€¢ Consider using sync.Pool for object reuse

ğŸš¨ COMMON MISTAKES:
âŒ Too many workers for CPU-bound tasks
âŒ Not implementing graceful shutdown
âŒ Unbounded job queues causing memory issues
âŒ Not handling worker panics
âŒ Blocking operations in worker functions
âŒ Not monitoring pool performance

ğŸ¯ REAL-WORLD USE CASES:
â€¢ Image/video processing pipelines
â€¢ HTTP request processing
â€¢ Database batch operations
â€¢ File processing and ETL
â€¢ Email sending systems
â€¢ Log processing and analysis
â€¢ API rate-limited operations

ğŸ” MONITORING AND DEBUGGING:
â€¢ Track active workers and queue sizes
â€¢ Measure job processing times
â€¢ Monitor error rates and types
â€¢ Use pprof for goroutine analysis
â€¢ Implement health checks
â€¢ Log worker lifecycle events

=============================================================================
*/